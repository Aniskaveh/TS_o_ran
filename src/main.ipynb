{
 "cells": [
  {
   "cell_type": "raw",
   "id": "506e1c9b",
   "metadata": {},
   "source": [
    "# Code for paper entitled: Empowering Traffic Steering in B5G Open  RAN  with Deep Reinforcement Learning\n",
    "# this paper uses 2 cooperative agents to learn RB scheduling policy for two slices (eMBB and uRLLC)\n",
    "# Author: Fatemeh.kavehmadavani@uni.lu\n",
    "# Last update date: 18-07-2023\n",
    "# Python version: 3.10.9\n",
    "# Tensorflow version: 2.12.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef0f769",
   "metadata": {},
   "source": [
    "# Step1:Import packages and set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac4033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxpy as cp\n",
    "from numpy.linalg import norm\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfd77d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rate_ur, mean_rate_em = 1.12, 21.12      #mean arrival rate of each uRLLC/embb user [packets/frame]\n",
    "length = 10000                                #number of observations\n",
    "T = 1000                                      #number of frames\n",
    "corr_factor = 0.95                            #correlation factor for time_series\n",
    "rho = 0.99                                    #correlation factor for channel\n",
    "U_ur, U_em, U = 2, 3, 5                       #number of uRLLC/embb users and all users\n",
    "M = 4                                         #number of RUs\n",
    "k_0, K, h_0 = 8, 10**0.5, 1                   #number of antenna in RU, Rician factor (db),Determinastic \n",
    "                                              #term of channel (LoS)\n",
    "BW = 10e+03                                   #Bandwidth of RUs (MHz)\n",
    "P_max = 10**4.3                               #maximum RU transmit power (43dBm)\n",
    "P_e = 10**-3                                  #error probibilaty\n",
    "N0 = 1e-11                                    #Power of AWGN noise (W)\n",
    "B_G = 180                                     #Guard band (kHz)\n",
    "beta1, beta2 = 360, 720                       #RB’s BW of numerology index 1,2 (kHz)\n",
    "delta1, delta2 = 0.25, 0.125                  #mini-slot’s duration of numerology index 1,2 (ms)\n",
    "Delta = 1                                     #each frame duration (ms)\n",
    "R_th = 10e+03                                 #minimum requirenment throughput for embb (10Mbps)\n",
    "Z_ur, Z_em = 0.5*8, 50*8                      #urllc packet size (0.5KB) and embb packet size (50KB)\n",
    "D_ur = 0.5                                    #delay requirenment of urllc (ms)\n",
    "G0 = 10**(5/10)                               #minimum SNR\n",
    "Q_max = 1e+09                                 #Checking the buffer\n",
    "R0, t0 = 1e+04, 1e-02                         #Refrence for data rate and latency\n",
    "f1, f2 = int(((BW-B_G)*0.7)/beta1), int((BW*0.3)/beta2)\n",
    "t1, t2 = int(Delta/delta1), int(Delta/delta2)\n",
    "\n",
    "dim2, dim1 = M*U*f2*t2, M*U*f1*t1             #number of dimenssion per slices\n",
    "em2_dims, em1_dims = M*U_em*f2*t2, M*U_em*f1*t1\n",
    "ur2_dims, ur1_dims = M*U_ur*f2*t2, M*U_ur*f1*t1\n",
    "\n",
    "nA2, nA1 = dim2, dim1                         #number of actions per slices\n",
    "nS2 = nA2 + 2*U_ur + U_em + 1 + 2*M*U                #number of states per slice 2(urllc)\n",
    "nS1 = nA1 + 2*U_ur + U_em + 1 + 2*M*U                #number of states per slice 1(embb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bdc14e",
   "metadata": {},
   "source": [
    "# Step2: Call topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8b1deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run topology.ipynb\n",
    "dis_ur, dis_em = topology(U_ur, U_em)   #distance of users from RUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023784c7",
   "metadata": {},
   "source": [
    "# Step3: LSTM predicts arrival packets at the first of each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d7cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict lambda\n",
    "%run LSTM.ipynb\n",
    "actual_lambda_ur, actual_lambda_em, predicted_lambda_ur, predicted_lambda_em = rAPP1(U_em, U_ur, mean_rate_ur, mean_rate_em, corr_factor, length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c51340",
   "metadata": {},
   "source": [
    "# Step4: Define Memory, and agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee1a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    \n",
    "    def __init__(self, max_size, input_dims1, n_actions1, input_dims2, n_actions2):\n",
    "        self.mem_size = max_size\n",
    "        self.mem_cntr = 0\n",
    "        self.state_memory1 = np.zeros((self.mem_size,input_dims1))\n",
    "        self.new_state_memory1 = np.zeros((self.mem_size,input_dims1))\n",
    "        self.action_memory1 = np.zeros((self.mem_size,n_actions1)) \n",
    "        self.reward_memory1 = np.zeros(self.mem_size)\n",
    "        self.state_memory2 = np.zeros((self.mem_size,input_dims2))\n",
    "        self.new_state_memory2 = np.zeros((self.mem_size,input_dims2))\n",
    "        self.action_memory2 = np.zeros((self.mem_size,n_actions2)) \n",
    "        self.reward_memory2 = np.zeros(self.mem_size)\n",
    "        self.flag = np.zeros(self.mem_size)\n",
    "        self.terminal_memory = np.zeros(self.mem_size) \n",
    "        \n",
    "    def store_transition(self, state1, action1, reward1, state_1, state2, action2, reward2, state_2, flag, done): \n",
    "        index = self.mem_cntr % self.mem_size \n",
    "        self.state_memory1[index] = state1\n",
    "        self.new_state_memory1[index] = state_1\n",
    "        self.action_memory1[index] = action1\n",
    "        self.reward_memory1[index] = reward1\n",
    "        self.state_memory2[index] = state2\n",
    "        self.new_state_memory2[index] = state_2\n",
    "        self.action_memory2[index] = action2\n",
    "        self.reward_memory2[index] = reward2\n",
    "        self.flag[index] = flag\n",
    "        self.terminal_memory[index] = 1 - int(done) \n",
    "        self.mem_cntr += 1\n",
    "        \n",
    "    def sample_buffer(self, batch_size):\n",
    "        max_mem = min(self.mem_cntr, self.mem_size)\n",
    "        batch = np.random.choice(max_mem, batch_size, replace = False)\n",
    "        states1 = self.state_memory1[batch]\n",
    "        new_states1 = self.new_state_memory1[batch]\n",
    "        actions1 = self.action_memory1[batch]\n",
    "        rewards1 = self.reward_memory1[batch]\n",
    "        states2 = self.state_memory2[batch]\n",
    "        new_states2 = self.new_state_memory2[batch]\n",
    "        actions2 = self.action_memory2[batch]\n",
    "        rewards2 = self.reward_memory2[batch]\n",
    "        flags = self.flag[batch]\n",
    "        terminal = self.terminal_memory[batch]\n",
    "        \n",
    "        return states1, actions1, rewards1, new_states1, states2, actions2, rewards2, new_states2, flags, terminal\n",
    "\n",
    "def binary_softmax2(x):\n",
    "    b_size = tf.shape(x)[0]\n",
    "    #tf.shape(x)[1]==>nA2\n",
    "    x2 = x[:,0:dim2]\n",
    "    y2 = tf.zeros_like(x2)      \n",
    "    for i in range(0, dim2, M*U):\n",
    "        pair = x2[:, i:i+M*U]\n",
    "        e_pair = tf.exp(pair - tf.reduce_max(pair, axis=1, keepdims=True))\n",
    "        softmax_pair = e_pair / tf.reduce_sum(e_pair, axis=1, keepdims=True)\n",
    "        for j in range(M*U):\n",
    "            indices = tf.stack([tf.range(b_size), tf.fill([b_size], i+j)], axis=1)\n",
    "            y2 = tf.tensor_scatter_nd_update(y2, indices, softmax_pair[:, j])    \n",
    "    y = tf.reshape(y2, (b_size,dim2)) \n",
    "    return y\n",
    "def binary_softmax1(x):\n",
    "    b_size = tf.shape(x)[0]\n",
    "    #tf.shape(x)[1]==>nA1\n",
    "    x1 = x[:,0:dim1]\n",
    "    y1 = tf.zeros_like(x1)      \n",
    "    for i in range(0, dim1, M*U):\n",
    "        pair = x1[:, i:i+M*U]\n",
    "        e_pair = tf.exp(pair - tf.reduce_max(pair, axis=1, keepdims=True))\n",
    "        softmax_pair = e_pair / tf.reduce_sum(e_pair, axis=1, keepdims=True)\n",
    "        for j in range(M*U):\n",
    "            indices = tf.stack([tf.range(b_size), tf.fill([b_size], i+j)], axis=1)\n",
    "            y1 = tf.tensor_scatter_nd_update(y1, indices, softmax_pair[:, j])    \n",
    "    y = tf.reshape(y1, (b_size,dim1)) \n",
    "    return y\n",
    "\n",
    "def build_ddqn2(lr, n_actions2, input_dims2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=256, input_shape=(input_dims2,) , activation='relu'))\n",
    "    model.add(Dense(units=input_dims2*2, activation='relu'))\n",
    "    model.add(Dense(units=input_dims2*3, activation='relu'))\n",
    "    model.add(Dense(units=n_actions2, activation='relu'))\n",
    "    model.add(Dense(units=n_actions2, activation= binary_softmax2))\n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss = 'binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "def build_ddqn1(lr, n_actions1, input_dims1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=256, input_shape=(input_dims1,) , activation='relu'))\n",
    "    model.add(Dense(units=input_dims1*2, activation='relu'))\n",
    "    model.add(Dense(units=input_dims1*3, activation='relu'))\n",
    "    model.add(Dense(units=n_actions1, activation='relu'))\n",
    "    model.add(Dense(units=n_actions1, activation= binary_softmax1))\n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss = 'binary_crossentropy')\n",
    "    return model     \n",
    "        \n",
    "class DDQNAgent_frq(object):\n",
    "    def __init__(self, alpha, gamma, epsilon, batch_size, n_actions2, input_dims2, n_actions1,\n",
    "                input_dims1, epsilon_end=0.01, mem_size=Q_max, fname2='agent2_.h5', fname1='agent1_.h5'):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.n_actions2 = n_actions2\n",
    "        self.input_dims2 = input_dims2\n",
    "        self.n_actions1 = n_actions1\n",
    "        self.input_dims1 = input_dims1\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_end\n",
    "        self.batch_size = batch_size\n",
    "        self.model_file2 = fname2\n",
    "        self.model_file1 = fname1\n",
    "        self.memory = ReplayBuffer(mem_size, input_dims1, n_actions1, input_dims2, n_actions2)\n",
    "        self.eval_net2 = build_ddqn2(self.alpha, self.n_actions2, self.input_dims2)\n",
    "        self.target_net2 = build_ddqn2(self.alpha, self.n_actions2, self.input_dims2)\n",
    "        self.target_net2.set_weights(self.eval_net2.get_weights())\n",
    "        self.eval_net1 = build_ddqn1(self.alpha, self.n_actions1, self.input_dims1)\n",
    "        self.target_net1 = build_ddqn1(self.alpha, self.n_actions1, self.input_dims1)\n",
    "        self.target_net1.set_weights(self.eval_net1.get_weights())\n",
    "        self.counter = 0\n",
    "\n",
    "    def remember(self, state1, action1, reward1, new_state1, state2, action2, reward2, new_state2, flag, done):        \n",
    "        self.memory.store_transition(state1, action1, reward1, new_state1,state2, action2, reward2, new_state2, flag, done)\n",
    "        \n",
    "    def choose_action2(self, state2, input_dims2): \n",
    "        if np.random.random() <= self.epsilon:\n",
    "            temp = np.random.random(self.n_actions2)\n",
    "            Action = temp.reshape(1,self.n_actions2)\n",
    "            moode = 'explore' \n",
    "        else:\n",
    "            state2 = state2.reshape(1,input_dims2)\n",
    "            Action = self.eval_net2.predict(state2)\n",
    "            moode = 'exploit'\n",
    "        #convert to binary\n",
    "        a2= Action[0][0:dim2]\n",
    "        b2= np.zeros(dim2)\n",
    "        for i in range(0, dim2, M*U):\n",
    "            pair = a2[i:i+M*U]\n",
    "            loc = np.where(pair == np.amax(pair))\n",
    "            b2[loc[0]+i] = 1         \n",
    "        action = b2     \n",
    "        return action, moode\n",
    "    \n",
    "    def choose_action1(self, state1, input_dims1): \n",
    "        if np.random.random() <= self.epsilon:\n",
    "            temp = np.random.random(self.n_actions1)\n",
    "            Action = temp.reshape(1,self.n_actions1)\n",
    "            moode = 'explore' \n",
    "        else:\n",
    "            state1 = state1.reshape(1,input_dims1)\n",
    "            Action = self.eval_net1.predict(state1)\n",
    "            moode = 'exploit'\n",
    "        #convert to binary\n",
    "        a1= Action[0][0:dim1]\n",
    "        b1= np.zeros(dim1)\n",
    "        for i in range(0, dim1, M*U):\n",
    "            pair = a1[i:i+M*U]\n",
    "            loc = np.where(pair == np.amax(pair))\n",
    "            b1[loc[0]+i] = 1         \n",
    "        action = b1     \n",
    "        return action, moode\n",
    "\n",
    "    def save_model(self):\n",
    "        self.eval_net2.save(self.model_file2)\n",
    "        self.eval_net1.save(self.model_file1)\n",
    "\n",
    "    def load_model(self):\n",
    "        self.eval_net2 = load_model(self.model_file2)\n",
    "        self.eval_net1 = load_model(self.model_file1)\n",
    "        \n",
    "    def learn(self):\n",
    "        if self.memory.mem_cntr < self.batch_size:\n",
    "            return\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            State1, Action1, Reward1, State_1, State2, Action2, Reward2, State_2, Flag, Done = self.memory.sample_buffer(self.batch_size)\n",
    "\n",
    "            q_pred2 = self.eval_net2.predict(State2)\n",
    "            q_eval2 = self.eval_net2.predict(State_2)\n",
    "            q_next2 = self.target_net2.predict(State_2)\n",
    "            q_target2 = np.copy(q_pred2)\n",
    "            \n",
    "            q_pred1 = self.eval_net1.predict(State1)\n",
    "            q_eval1 = self.eval_net1.predict(State_1)\n",
    "            q_next1 = self.target_net1.predict(State_1)\n",
    "            q_target1 = np.copy(q_pred1)\n",
    "\n",
    "            batch_index = np.arange(self.batch_size)\n",
    "\n",
    "            for i in batch_index:\n",
    "                #convert to binary\n",
    "                a2 = q_eval2[i][0:dim2]\n",
    "                b2 = np.zeros(dim2)\n",
    "                for ii in range(0, dim2, M*U):\n",
    "                    pair = a2[ii:ii+M*U]\n",
    "                    loc = np.where(pair == np.amax(pair))\n",
    "                    b2[loc[0]+ii] = 1       \n",
    "                q_eval2_binary = b2\n",
    "                bb = q_eval2_binary*q_next2[i] # DDQN model               \n",
    "                for j in range(self.n_actions2):\n",
    "                    if int(Action2[i][j])==1:\n",
    "                        q_target2[i][j] = Reward2[i] + (self.gamma*(bb[j]))*Done[i]*Flag[i]\n",
    "                #convert to binary\n",
    "                a1 = q_eval1[i][0:dim1]\n",
    "                b1 = np.zeros(dim1)\n",
    "                for ii in range(0, dim1, M*U):\n",
    "                    pair = a1[ii:ii+M*U]\n",
    "                    loc = np.where(pair == np.amax(pair))\n",
    "                    b1[loc[0]+ii] = 1       \n",
    "                q_eval1_binary = b1\n",
    "                bb = q_eval1_binary*q_next1[i] # DDQN model               \n",
    "                for j in range(self.n_actions1):\n",
    "                    if int(Action1[i][j])==1:\n",
    "                        q_target1[i][j] = Reward1[i] + (self.gamma*(bb[j]))*Done[i]*Flag[i]\n",
    "\n",
    "            history2 = self.eval_net2.fit(State2, q_target2, verbose=0)\n",
    "            loss2 = history2.history['loss']\n",
    "            history1 = self.eval_net1.fit(State1, q_target1, verbose=0)\n",
    "            loss1 = history1.history['loss']\n",
    "\n",
    "            if self.counter % 1000 == 0:\n",
    "                self.target_net2.set_weights(self.eval_net2.get_weights())\n",
    "                self.target_net1.set_weights(self.eval_net1.get_weights())\n",
    "                print('target networks are updating...')\n",
    "                \n",
    "            decay_steps = 3500\n",
    "            if self.memory.mem_cntr%decay_steps == 0:\n",
    "                epoch = self.memory.mem_cntr\n",
    "                def lr_update(epoch):\n",
    "                    initial_lr = 0.001\n",
    "                    decay_rate = 0.5\n",
    "                    new_lr = initial_lr * math.pow(decay_rate, math.floor(epoch / decay_steps))\n",
    "                    return new_lr\n",
    "                # Create learning rate scheduler callback\n",
    "                lr_scheduler = LearningRateScheduler(lr_update)\n",
    "                history2 = self.eval_net2.fit(State2, q_target2, verbose=0, callbacks=[lr_scheduler])\n",
    "                loss2 = history2.history['loss']\n",
    "                history1 = self.eval_net1.fit(State1, q_target1, verbose=0, callbacks=[lr_scheduler])\n",
    "                loss1 = history1.history['loss']\n",
    "                print('learning rate is updating...')\n",
    "                \n",
    "            self.epsilon = self.epsilon * 0.9999 if self.epsilon > self.epsilon_min else self.epsilon_min\n",
    "\n",
    "            if self.epsilon <= self.epsilon_min:\n",
    "                self.target_net2.set_weights(self.eval_net2.get_weights())\n",
    "                self.target_net1.set_weights(self.eval_net1.get_weights())\n",
    "            \n",
    "            return np.mean(loss2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129ae3e7",
   "metadata": {},
   "source": [
    "# Step5: Initialize parameters at the frame 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5091c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_frq(frame):   \n",
    "    #Uniform flow-split variable----------------> Q[-1]\n",
    "    V = np.zeros((M,U))      \n",
    "    for u in range(U):\n",
    "        for m in range(M):\n",
    "            V[m,u] = 1/M\n",
    "    V_ = V.reshape((M*U),1)\n",
    "    #empty queue at first frame-----------------> q[-1]\n",
    "    q = np.zeros((M,U))\n",
    "    q_ = q.reshape((M*U),1)\n",
    "    #Channel gain of previous frame------------->G[-1]\n",
    "    g_em2, g_em1 = np.zeros((M,U_em,f2, t2)), np.zeros((M,U_em,f1, t1))\n",
    "    g_ur2, g_ur1 = np.zeros((M,U_ur,f2, t2)), np.zeros((M,U_ur,f1, t1))\n",
    "    H_ur1, H_em1, H_ur2, H_em2 = [], [], [], []\n",
    "    pl_em2, pl_ur2 = np.zeros((M,U_em)), np.zeros((M,U_ur))\n",
    "    pl_em1, pl_ur1 = np.zeros((M,U_em)), np.zeros((M,U_ur))\n",
    "    for m in range(M):\n",
    "        for u in range(U_em):\n",
    "            PL = 128.1 + (37.6 * np.log10(dis_em[m][u]* (10**-3)))  #pathloss\n",
    "            PLdec = np.sqrt(10**(-PL/10)/N0)\n",
    "            pl_em2[m,u] = PLdec\n",
    "            for f in range(f2):\n",
    "                H, Hfading = [], []\n",
    "                h = np.sqrt(k_0/2)* (np.random.randn(1)+ 1j*np.random.randn(1))\n",
    "                H.append(PLdec*h)\n",
    "                Hfading.append(h)\n",
    "                g_em2[m,u,f,0] = (norm(H[0],2)**2)\n",
    "                for t in range(1,t2):\n",
    "                    temp = np.sqrt(rho)*Hfading[t-1]+(np.sqrt(1-rho)* \\\n",
    "                            (np.sqrt(k_0/2))* (np.random.randn(1)+ 1j*np.random.randn(1)))\n",
    "                    Hfading.append(temp)\n",
    "                    H.append(PLdec*temp)\n",
    "                    g_em2[m,u,f,t] = (norm(H[t],2)**2)\n",
    "                H_em2.append(temp)\n",
    "        for u in range(U_ur):\n",
    "            PL = 128.1 + (37.6 * np.log10(dis_ur[m][u]* (10**-3)))  #pathloss\n",
    "            PLdec = np.sqrt(10**(-PL/10)/N0)\n",
    "            pl_ur2[m,u] = PLdec\n",
    "            for f in range(f2):\n",
    "                H, Hfading = [], []\n",
    "                h = np.sqrt(k_0/2)* (np.random.randn(1)+ 1j*np.random.randn(1))\n",
    "                H.append(PLdec*h)\n",
    "                Hfading.append(h)\n",
    "                g_ur2[m,u,f,0] = (norm(H[0],2)**2)\n",
    "                for t in range(1,t2):\n",
    "                    temp = np.sqrt(rho)*Hfading[t-1]+(np.sqrt(1-rho)* \\\n",
    "                            (np.sqrt(k_0/2))* (np.random.randn(1)+ 1j*np.random.randn(1)))\n",
    "                    Hfading.append(temp)\n",
    "                    H.append(PLdec*temp)\n",
    "                    g_ur2[m,u,f,t] = (norm(H[t],2)**2)\n",
    "                H_ur2.append(PLdec*temp)\n",
    "    for m in range(M):\n",
    "        for u in range(U_em):\n",
    "            PL = 128.1 + (37.6 * np.log10(dis_em[m][u]* (10**-3)))  #pathloss\n",
    "            PLdec = np.sqrt(10**(-PL/10)/N0)\n",
    "            pl_em1[m,u] = PLdec\n",
    "            for f in range(f1):\n",
    "                H, Hfading = [], []\n",
    "                h = np.sqrt(k_0/2)* (np.random.randn(1)+ 1j*np.random.randn(1))\n",
    "                H.append(PLdec*h)\n",
    "                Hfading.append(h)\n",
    "                g_em1[m,u,f,0] = (norm(H[0],2)**2)\n",
    "                for t in range(1,t1):\n",
    "                    temp = np.sqrt(rho)*Hfading[t-1]+(np.sqrt(1-rho)* \\\n",
    "                            (np.sqrt(k_0/2))* (np.random.randn(1)+ 1j*np.random.randn(1)))\n",
    "                    Hfading.append(temp)\n",
    "                    H.append(PLdec*temp)\n",
    "                    g_em1[m,u,f,t] = (norm(H[t],2)**2)\n",
    "                H_em1.append(temp)\n",
    "        for u in range(U_ur):\n",
    "            PL = 128.1 + (37.6 * np.log10(dis_ur[m][u]* (10**-3)))  #pathloss\n",
    "            PLdec = np.sqrt(10**(-PL/10)/N0)\n",
    "            pl_ur1[m,u] = PLdec\n",
    "            for f in range(f1):\n",
    "                H, Hfading = [], []\n",
    "                h = np.sqrt(k_0/2)* (np.random.randn(1)+ 1j*np.random.randn(1))\n",
    "                H.append(PLdec*h)\n",
    "                Hfading.append(h)\n",
    "                g_ur1[m,u,f,0] = (norm(H[0],2)**2)\n",
    "                for t in range(1,t1):\n",
    "                    temp = np.sqrt(rho)*Hfading[t-1]+(np.sqrt(1-rho)* \\\n",
    "                            (np.sqrt(k_0/2))* (np.random.randn(1)+ 1j*np.random.randn(1)))\n",
    "                    Hfading.append(temp)\n",
    "                    H.append(PLdec*temp)\n",
    "                    g_ur1[m,u,f,t] = (norm(H[t],2)**2)\n",
    "                H_ur1.append(PLdec*temp)\n",
    "                \n",
    "    p_em2, p_em1 = np.zeros((M,U_em,f2, t2)), np.zeros((M,U_em,f1, t1))\n",
    "    p_ur2, p_ur1 = np.zeros((M,U_ur,f2, t2)), np.zeros((M,U_ur,f1, t1))\n",
    "    pp = P_max/(U*(f1+(2*f2)))\n",
    "    for m in range(M):\n",
    "        for t in range(t1):\n",
    "            p_em1[m,:,:,t] = pp*np.ones((U_em,f1))\n",
    "            p_ur1[m,:,:,t] = pp*np.ones((U_ur,f1))\n",
    "        for t in range(t2):\n",
    "            p_em2[m,:,:,t] = pp*np.ones((U_em,f2))\n",
    "            p_ur2[m,:,:,t] = pp*np.ones((U_ur,f2))\n",
    "\n",
    "    G_ur2, G_ur1 = (g_ur2*p_ur2).reshape(ur2_dims,1), (g_ur1*p_ur1).reshape(ur1_dims,1)\n",
    "    G_em2, G_em1 = (g_em2*p_em2).reshape(em2_dims,1), (g_em1*p_em1).reshape(em1_dims,1)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(G_ur2)\n",
    "    G_ur2_norm = scaler.transform(G_ur2)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(G_em2)\n",
    "    G_em2_norm = scaler.transform(G_em2)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(G_ur1)\n",
    "    G_ur1_norm = scaler.transform(G_ur1)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(G_em1)\n",
    "    G_em1_norm = scaler.transform(G_em1)\n",
    "    \n",
    "    e_ur1, e_ur2, w1 = np.zeros(U_ur), np.zeros(U_ur), np.zeros(U_ur)\n",
    "    s1, s2 = 0, 0\n",
    "    for u in range(U_ur):\n",
    "        w = (predicted_lambda_ur[frame,u]/np.sum(predicted_lambda_ur[frame,0:U_ur]))*f2*int(t2/2)\n",
    "        e_ur2[u] = np.floor(np.minimum(predicted_lambda_ur[frame,u],w))\n",
    "        s2 += e_ur2[u]\n",
    "        w1[u] = np.round((np.maximum((predicted_lambda_ur[frame,u]- e_ur2[u]),0)/2))\n",
    "    for u in range(U_ur):\n",
    "        if np.sum(w1)!=0:\n",
    "            e_ur1[u] = np.floor(np.minimum(((w1[u]/np.sum(w1))*f1*int(t1/2)),w1[u]))\n",
    "        else:\n",
    "            e_ur1[u] = 0\n",
    "        s1 +=e_ur1[u]\n",
    "        \n",
    "    e_em1 = np.maximum(int(np.floor(f1*t1 - s1)),0)\n",
    "    e_em2 = np.maximum(int(np.floor(f2*t2 - s2)),0)\n",
    "    e_ur1 = e_ur1.reshape(U_ur,1)\n",
    "    e_ur2 = e_ur2.reshape(U_ur,1)\n",
    "    EE1 = np.vstack((e_ur1, e_em1))\n",
    "    EE2 = np.vstack((e_ur2, e_em2))\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(EE1)\n",
    "    EE1_norm = scaler.transform(EE1)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(EE2)\n",
    "    EE2_norm = scaler.transform(EE2)\n",
    "    \n",
    "    lam_ur = predicted_lambda_ur[frame,0:U_ur].reshape(U_ur,1)\n",
    "    lam_em = predicted_lambda_em[frame,:].reshape(U_em,1)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(lam_ur)\n",
    "    lam_ur_norm = scaler.transform(lam_ur)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(lam_em)\n",
    "    lam_em_norm = scaler.transform(lam_em)\n",
    "    \n",
    "    state2 = np.concatenate((EE2_norm, lam_ur_norm, lam_em_norm, G_ur2_norm, G_em2_norm, q_, V_))    \n",
    "    state1 = np.concatenate((EE1_norm, lam_ur_norm, lam_em_norm, G_ur1_norm, G_em1_norm, q_, V_))\n",
    "\n",
    "    return H_ur1, H_ur2, H_em1, H_em2, pl_ur1, pl_ur2, pl_em1, pl_em2, state1, state2,V, q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e1cdc3",
   "metadata": {},
   "source": [
    "# Step6: Design environment based on our network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f760bb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def envornmt_frq(pi_ur1, pi_em1, pi_ur2, pi_em2, frame, end_frame, P_max, H_ur1, H_ur2, H_em1,\n",
    "                 H_em2, pl_ur1, pl_ur2, pl_em1, pl_em2,V,q):\n",
    "    \n",
    "    Reward1, Reward2 = 0, 0\n",
    "    #Check the feasibility of \\pi based on constrains of 9b, 9g \n",
    "    Flag1, Flag2 = 1, 1\n",
    "    e_ur1, e_ur2, w1 = np.zeros(U_ur), np.zeros(U_ur), np.zeros(U_ur)\n",
    "    s1, s2 = 0, 0\n",
    "    for u in range(U_ur):\n",
    "        w = (actual_lambda_ur[frame,u]/np.sum(actual_lambda_ur[frame,0:U_ur]))*f2*int(t2/2)\n",
    "        e_ur2[u] = np.floor(np.minimum(actual_lambda_ur[frame,u],w))\n",
    "        s2 += e_ur2[u]\n",
    "        w1[u] = np.round((np.maximum((actual_lambda_ur[frame,u]- e_ur2[u]),0)/2))\n",
    "    for u in range(U_ur):\n",
    "        if np.sum(w1)!=0:\n",
    "            e_ur1[u] = np.floor(np.minimum(((w1[u]/np.sum(w1))*f1*int(t1/2)),w1[u]))\n",
    "        else:\n",
    "            e_ur1[u] = 0\n",
    "        s1 +=e_ur1[u]        \n",
    "    e_em1 = np.maximum(int(np.floor(f1*t1 - s1)),0)\n",
    "    e_em2 = np.maximum(int(np.floor(f2*t2 - s2)),0)\n",
    "    print('e_ur1, e_ur2', e_ur1, e_ur2)\n",
    "    print('e_em1, e_em2', e_em1, e_em2)\n",
    "    \n",
    "    for u in range(U_ur):\n",
    "        if np.sum(pi_ur2[:,u,:,:])>=e_ur2[u]:\n",
    "            Flag2 *= 1\n",
    "            Reward2 +=1\n",
    "        else:\n",
    "            Flag2 *= 0\n",
    "            print('OooooOps ... pi_ur2 is not met!!!!')\n",
    "        if np.sum(pi_ur1[:,u,:,:])>=e_ur1[u]:\n",
    "            Flag1 *= 1\n",
    "            Reward1 +=1\n",
    "        else:\n",
    "            Flag1 *= 0\n",
    "            print('OooooOps ... pi_ur1 is not met!!!!')\n",
    "    if Flag1==1:\n",
    "        Reward1 +=2\n",
    "    if Flag2==1:\n",
    "        Reward2 +=2\n",
    "    if np.sum(pi_em1)>=e_em1:\n",
    "        Reward1 +=3\n",
    "    if np.sum(pi_em2)>=e_em2:\n",
    "        Reward2 +=3\n",
    "        \n",
    "    #check the uRLLC constraint\n",
    "    temp1, temp2 = [], []\n",
    "    for u in range(U_ur):\n",
    "        aa = []\n",
    "        for m in range(M):\n",
    "            for f in range(f2):\n",
    "                a = pi_ur2[m,u,f,:]\n",
    "                if int(np.max(a))==1:\n",
    "                    noise = np.array(range(len(a)))*1e-12\n",
    "                    aa.append((np.argmax(a+noise)+1)*delta2)\n",
    "                else:\n",
    "                    aa.append((np.argmax(a))*delta2)\n",
    "        temp2.append(np.max(aa))\n",
    "        if np.max(aa)>0 and np.max(aa)<= D_ur:\n",
    "            Flag2 *= 1\n",
    "            Reward2 +=2\n",
    "        else:\n",
    "            Flag2 *= 0\n",
    "            print('OooooOps ... latency is not met!!!!')\n",
    "            Reward2 += -3\n",
    "    for u in range(U_ur):\n",
    "        aa = []\n",
    "        for m in range(M):     \n",
    "            for f in range(f1):\n",
    "                a = pi_ur1[m,u,f,:]\n",
    "                if int(np.max(a))==1:\n",
    "                    noise = np.array(range(len(a)))*1e-12\n",
    "                    aa.append((np.argmax(a+noise)+1)*delta1)\n",
    "                else:\n",
    "                    aa.append((np.argmax(a))*delta1)\n",
    "        temp1.append(np.max(aa))\n",
    "        if np.max(aa)<= D_ur:\n",
    "            Flag1 *= 1\n",
    "            Reward1 +=2\n",
    "        else:\n",
    "            Flag1 *= 0\n",
    "            print('OooooOps ... latency is not met!!!!')\n",
    "            Reward1 += -3\n",
    "    t_ur1, t_ur2 = np.max(temp1), np.max(temp2)\n",
    "    print('t_ur1, t_ur2', t_ur1, t_ur2)\n",
    "    if Flag1==1:\n",
    "        Reward1 +=4\n",
    "    if Flag2==1:\n",
    "        Reward2 +=4\n",
    "    \n",
    "    # creating channel for current state-----> G[0]\n",
    "    g_em2, g_ur2 = np.zeros((M,U_em,f2, t2)), np.zeros((M,U_ur,f2, t2))\n",
    "    g_em1, g_ur1 = np.zeros((M,U_em,f1, t1)), np.zeros((M,U_ur,f1, t1))\n",
    "    h_em2, h_ur2 = np.array(H_em2), np.array(H_ur2)\n",
    "    h_em1, h_ur1 = np.array(H_em1), np.array(H_ur1)\n",
    "    hh_em2, hh_ur2 = h_em2.reshape(M,U_em,f2, 1), h_ur2.reshape(M,U_ur,f2, 1)\n",
    "    hh_em1, hh_ur1 = h_em1.reshape(M,U_em,f1, 1), h_ur1.reshape(M,U_ur,f1, 1)\n",
    "    H_em2, H_ur2,H_em1, H_ur1 = [], [], [], []    \n",
    "    for m in range(M):\n",
    "        for u in range(U_em):\n",
    "            for f in range(f2):\n",
    "                H, Hfading = [], []\n",
    "                for t in range(t2):\n",
    "                    if t==0:\n",
    "                        temp = np.sqrt(rho)*hh_em2[m,u,f]+(np.sqrt(1-rho)* \\\n",
    "                            (np.sqrt(k_0/2))* (np.random.randn(1)+ 1j*np.random.randn(1)))\n",
    "                        Hfading.append(temp)\n",
    "                        H.append(pl_em2[m,u]*temp)\n",
    "                        g_em2[m,u,f,t] = (norm(H[t],2)**2)\n",
    "                    else:\n",
    "                        temp = np.sqrt(rho)*Hfading[t-1]+(np.sqrt(1-rho)* \\\n",
    "                            (np.sqrt(k_0/2))* (np.random.randn(1)+ 1j*np.random.randn(1)))\n",
    "                        Hfading.append(temp)\n",
    "                        H.append(pl_em2[m,u]*temp)\n",
    "                        g_em2[m,u,f,t] = (norm(H[t],2)**2)\n",
    "                H_em2.append(temp)\n",
    "        for u in range(U_ur):\n",
    "            for f in range(f2):\n",
    "                H, Hfading = [], []\n",
    "                for t in range(t2):\n",
    "                    if t==0:\n",
    "                        temp = np.sqrt(rho)*hh_ur2[m,u,f]+(np.sqrt(1-rho)* \\\n",
    "                            (np.sqrt(k_0/2))* (np.random.randn(1)+ 1j*np.random.randn(1)))\n",
    "                        Hfading.append(temp)\n",
    "                        H.append(pl_ur2[m,u]*temp)\n",
    "                        g_ur2[m,u,f,t] = (norm(H[t],2)**2)\n",
    "                    else:\n",
    "                        temp = np.sqrt(rho)*Hfading[t-1]+(np.sqrt(1-rho)* \\\n",
    "                            (np.sqrt(k_0/2))* (np.random.randn(1)+ 1j*np.random.randn(1)))\n",
    "                        Hfading.append(temp)\n",
    "                        H.append(pl_ur2[m,u]*temp)\n",
    "                        g_ur2[m,u,f,t] = (norm(H[t],2)**2)\n",
    "                H_ur2.append(temp)\n",
    "    for m in range(M):\n",
    "        for u in range(U_em):\n",
    "            for f in range(f1):\n",
    "                H, Hfading = [], []\n",
    "                for t in range(t1):\n",
    "                    if t==0:\n",
    "                        temp = np.sqrt(rho)*hh_em1[m,u,f]+(np.sqrt(1-rho)* \\\n",
    "                            (np.sqrt(k_0/2))* (np.random.randn(1)+ 1j*np.random.randn(1)))\n",
    "                        Hfading.append(temp)\n",
    "                        H.append(pl_em1[m,u]*temp)\n",
    "                        g_em1[m,u,f,t] = (norm(H[t],2)**2)\n",
    "                    else:\n",
    "                        temp = np.sqrt(rho)*Hfading[t-1]+(np.sqrt(1-rho)* \\\n",
    "                            (np.sqrt(k_0/2))* (np.random.randn(1)+ 1j*np.random.randn(1)))\n",
    "                        Hfading.append(temp)\n",
    "                        H.append(pl_em1[m,u]*temp)\n",
    "                        g_em1[m,u,f,t] = (norm(H[t],2)**2)\n",
    "                H_em1.append(temp)\n",
    "        for u in range(U_ur):\n",
    "            for f in range(f1):\n",
    "                H, Hfading = [], []\n",
    "                for t in range(t1):\n",
    "                    if t==0:\n",
    "                        temp = np.sqrt(rho)*hh_ur1[m,u,f]+(np.sqrt(1-rho)* \\\n",
    "                            (np.sqrt(k_0/2))* (np.random.randn(1)+ 1j*np.random.randn(1)))\n",
    "                        Hfading.append(temp)\n",
    "                        H.append(pl_ur1[m,u]*temp)\n",
    "                        g_ur1[m,u,f,t] = (norm(H[t],2)**2)\n",
    "                    else:\n",
    "                        temp = np.sqrt(rho)*Hfading[t-1]+(np.sqrt(1-rho)* \\\n",
    "                            (np.sqrt(k_0/2))* (np.random.randn(1)+ 1j*np.random.randn(1)))\n",
    "                        Hfading.append(temp)\n",
    "                        H.append(pl_ur1[m,u]*temp)\n",
    "                        g_ur1[m,u,f,t] = (norm(H[t],2)**2)\n",
    "                H_ur1.append(temp)\n",
    "    rr_em = 0\n",
    "    #goes to xAPP to obtain optimized power and calculate the final reward for each slice\n",
    "    if Flag1==1 and Flag2==1:\n",
    "        ReWard1, ReWard2, Flag1, Flag2, V, q, p_ur2, p_ur1, p_em2, p_em1, rr_em = xAPP(pi_ur1,pi_ur2,pi_em1,pi_em2,frame,P_max,Flag1,Flag2,\n",
    "                                                    g_ur1,g_em1,g_ur2,g_em2,e_ur1,e_em1,e_ur2,e_em2,V,q)\n",
    "        Reward2 += (ReWard2/R0)\n",
    "        Reward1 += (ReWard1/R0)\n",
    "        print('ReWard1/R0, ReWard2/R0', ReWard1/R0, ReWard2/R0)\n",
    "    else:\n",
    "        #update queue length\n",
    "        for m in range(M):\n",
    "            for u in range(U_ur):\n",
    "                q[m,u] += (V[m,u]*actual_lambda_ur[frame,u]*Z_ur*Delta*1e-03)\n",
    "            for u in range(U_em):\n",
    "                q[m,u+U_ur] += (V[m,u+U_ur]*actual_lambda_em[frame,u]*Z_em*Delta)\n",
    "        #update flow split vector\n",
    "        V = np.zeros((M,U))      \n",
    "        for u in range(U):\n",
    "            for m in range(M):\n",
    "                V[m,u] = 1/M\n",
    "        #update power\n",
    "        p_em2, p_em1 = np.zeros((M,U_em,f2, t2)), np.zeros((M,U_em,f1, t1))\n",
    "        p_ur2, p_ur1 = np.zeros((M,U_ur,f2, t2)), np.zeros((M,U_ur,f1, t1))\n",
    "        pp = P_max/(U*(f1+(2*f2)))\n",
    "        for m in range(M):\n",
    "            for t in range(t1):\n",
    "                p_em1[m,:,:,t] = pp*np.ones((U_em,f1))\n",
    "                p_ur1[m,:,:,t] = pp*np.ones((U_ur,f1))\n",
    "            for t in range(t2):\n",
    "                p_em2[m,:,:,t] = pp*np.ones((U_em,f2))\n",
    "                p_ur2[m,:,:,t] = pp*np.ones((U_ur,f2))\n",
    "        \n",
    "    # checks if reachs the final frame and over the episode or not\n",
    "    if frame == end_frame-1:\n",
    "        done= True\n",
    "    else:\n",
    "        done= False\n",
    "        \n",
    "    #new_state\n",
    "    G_ur2, G_ur1 = (g_ur2*p_ur2).reshape(ur2_dims,1), (g_ur1*p_ur1).reshape(ur1_dims,1)\n",
    "    G_em2, G_em1 = (g_em2*p_em2).reshape(em2_dims,1), (g_em1*p_em1).reshape(em1_dims,1)    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(G_ur2)\n",
    "    G_ur2_norm = scaler.transform(G_ur2)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(G_em2)\n",
    "    G_em2_norm = scaler.transform(G_em2)   \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(G_ur1)\n",
    "    G_ur1_norm = scaler.transform(G_ur1)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(G_em1)\n",
    "    G_em1_norm = scaler.transform(G_em1)\n",
    "    \n",
    "    e_ur1, e_ur2, w1 = np.zeros(U_ur), np.zeros(U_ur), np.zeros(U_ur)\n",
    "    s1, s2 = 0, 0\n",
    "    for u in range(U_ur):\n",
    "        w = (predicted_lambda_ur[frame,u]/np.sum(predicted_lambda_ur[frame+1,0:U_ur]))*f2*int(t2/2)\n",
    "        e_ur2[u] = np.floor(np.minimum(predicted_lambda_ur[frame+1,u],w))\n",
    "        s2 += e_ur2[u]\n",
    "        w1[u] = np.round((np.maximum((predicted_lambda_ur[frame+1,u]- e_ur2[u]),0)/2))\n",
    "    for u in range(U_ur):\n",
    "        if np.sum(w1)!=0:\n",
    "            e_ur1[u] = np.floor(np.minimum(((w1[u]/np.sum(w1))*f1*int(t1/2)),w1[u]))\n",
    "        else:\n",
    "            e_ur1[u] = 0\n",
    "        s1 +=e_ur1[u]\n",
    "        \n",
    "    e_em1 = np.maximum(int(np.floor(f1*t1 - s1)),0)\n",
    "    e_em2 = np.maximum(int(np.floor(f2*t2 - s2)),0)\n",
    "    e_ur1 = e_ur1.reshape(U_ur,1)\n",
    "    e_ur2 = e_ur2.reshape(U_ur,1)\n",
    "    EE1 = np.vstack((e_ur1, e_em1))\n",
    "    EE2 = np.vstack((e_ur2, e_em2))\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(EE1)\n",
    "    EE1_norm = scaler.transform(EE1)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(EE2)\n",
    "    EE2_norm = scaler.transform(EE2)\n",
    "    \n",
    "    lam_ur = predicted_lambda_ur[frame+1,0:U_ur].reshape(U_ur,1)\n",
    "    lam_em = predicted_lambda_em[frame+1,:].reshape(U_em,1)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(lam_ur)\n",
    "    lam_ur_norm = scaler.transform(lam_ur)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(lam_em)\n",
    "    lam_em_norm = scaler.transform(lam_em)\n",
    "    \n",
    "    q_ = q.reshape((M*U),1)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(q_)\n",
    "    q_norm = scaler.transform(q_)\n",
    "    \n",
    "    V_ = V.reshape((M*U,1))\n",
    "    \n",
    "    state_2 = np.concatenate((EE2_norm, lam_ur_norm, lam_em_norm, G_ur2_norm, G_em2_norm,q_norm, V_))    \n",
    "    state_1 = np.concatenate((EE1_norm, lam_ur_norm, lam_em_norm, G_ur1_norm, G_em1_norm,q_norm, V_))\n",
    "    \n",
    "    if Flag1==1 and Flag2==1:\n",
    "        Flag=1\n",
    "    else:\n",
    "        Flag=0\n",
    "    \n",
    "    return state_1, state_2, Reward1, Reward2, done, H_ur1, H_em1, H_ur2, H_em2, V, q, Flag , rr_em, np.maximum(t_ur1, t_ur2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801826a4",
   "metadata": {},
   "source": [
    "# xAPP solves short-scale sub-problem to obtain optimal power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d2777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xAPP(pi_ur1,pi_ur2,pi_em1,pi_em2,frame,P_max,Flag1,Flag2,g_ur1,g_em1,g_ur2,g_em2,e_ur1,e_em1,e_ur2,e_em2,V,q):\n",
    "\n",
    "    J = 0.3257    \n",
    "    try:\n",
    "        y_ur1, y_em1, y_ur2, y_em2 = {},{},{},{}\n",
    "        for m in range(M):\n",
    "            for u in range(U_em):\n",
    "                for f in range(f2):\n",
    "                    for t in range(t2):\n",
    "                            y_em2[(m,u,f,t)]= cp.Variable()\n",
    "                for f in range(f1):\n",
    "                    for t in range(t1):\n",
    "                            y_em1[(m,u,f,t)]= cp.Variable()\n",
    "            for u in range(U_ur):\n",
    "                for f in range(f2):\n",
    "                    for t in range(t2):\n",
    "                            y_ur2[(m,u,f,t)]= cp.Variable()\n",
    "                for f in range(f1):\n",
    "                    for t in range(t1):\n",
    "                            y_ur1[(m,u,f,t)]= cp.Variable()\n",
    "\n",
    "        #objective function\n",
    "        obj = 0\n",
    "        for m in range(M):\n",
    "            for u in range(U_em):\n",
    "                for f in range(f2):\n",
    "                    for t in range(t2):\n",
    "                        obj += ((beta2/0.6931)*(cp.log(1+(g_em2[m,u,f,t]*y_em2[m,u,f,t]))))\n",
    "                for f in range(f1):\n",
    "                    for t in range(t1):\n",
    "                        obj += ((beta1/0.6931)*(cp.log(1+(g_em1[m,u,f,t]*y_em1[m,u,f,t]))))\n",
    "\n",
    "        objective= cp.Maximize(obj)\n",
    "        constraint= []\n",
    "\n",
    "        for m in range(M):\n",
    "            for u in range(U_em):\n",
    "                for f in range(f2):\n",
    "                    for t in range(t2):                       \n",
    "                        constraint.append(y_em2[m,u,f,t] <= (P_max*pi_em2[m,u,f,t]))  \n",
    "                        constraint.append(y_em2[m,u,f,t] >=0)\n",
    "                for f in range(f1):\n",
    "                    for t in range(t1):                       \n",
    "                        constraint.append(y_em1[m,u,f,t] <= (P_max*pi_em1[m,u,f,t]))  \n",
    "                        constraint.append(y_em1[m,u,f,t] >=0)\n",
    "            for u in range(U_ur):\n",
    "                for f in range(f2):\n",
    "                    for t in range(t2):                       \n",
    "                        constraint.append(y_ur2[m,u,f,t] <= (P_max*pi_ur2[m,u,f,t]))  \n",
    "                        constraint.append(y_ur2[m,u,f,t] >= (pi_ur2[m,u,f,t]*(G0/g_ur2[m,u,f,t])))\n",
    "                for f in range(f1):\n",
    "                    for t in range(t1):                       \n",
    "                        constraint.append(y_ur1[m,u,f,t] <= (P_max*pi_ur1[m,u,f,t]))  \n",
    "                        constraint.append(y_ur1[m,u,f,t] >= (pi_ur1[m,u,f,t]*(G0/g_ur1[m,u,f,t])))\n",
    "\n",
    "        for m in range(M):\n",
    "            for t in range(t1):\n",
    "                temp0= 0\n",
    "                for f in range(f1):\n",
    "                    for u in range(U_ur):\n",
    "                        temp0 += y_ur1[m,u,f,t]\n",
    "                    for u in range(U_em):\n",
    "                        temp0 += y_em1[m,u,f,t]\n",
    "                for f in range(f2):\n",
    "                    for u in range(U_ur):\n",
    "                        temp0 += y_ur2[m,u,f,2*t] + y_ur2[m,u,f,2*t+1]\n",
    "                    for u in range(U_em):\n",
    "                        temp0 += y_em2[m,u,f,2*t] + y_em2[m,u,f,2*t+1]\n",
    "                constraint.append(temp0<=P_max)\n",
    "        #embb & urllc QoS Constraints\n",
    "        for u in range(U_em):\n",
    "            #temp2= 0\n",
    "            for m in range(M):\n",
    "                temp2= 0\n",
    "                for t in range(t2):\n",
    "                    for f in range(f2):\n",
    "                        temp2 += ((beta2/0.6931)*cp.log(1+(g_em2[m,u,f,t]*y_em2[m,u,f,t])))\n",
    "                for t in range(t1):\n",
    "                    for f in range(f1):\n",
    "                        temp2 += ((beta1/0.6931)*cp.log(1+(g_em1[m,u,f,t]*y_em1[m,u,f,t])))\n",
    "                constraint.append(temp2>=V[m,u+U_ur]*actual_lambda_em[frame,u]*Z_em*Delta)\n",
    "        for u in range(U_ur):\n",
    "            temp3 = 0\n",
    "            for m in range(M):\n",
    "                #temp3 = 0\n",
    "                for f in range(f2):\n",
    "                    for t in range(t2):\n",
    "                        temp3 += ((beta2/0.6931)*(cp.log(1+(g_ur2[m,u,f,t]*y_ur2[m,u,f,t]))))-\\\n",
    "                                 (beta2*pi_ur2[m,u,f,t]*J)\n",
    "                for f in range(f1):\n",
    "                    for t in range(t1):\n",
    "                        temp3 += ((beta1/0.6931)*(cp.log(1+(g_ur1[m,u,f,t]*y_ur1[m,u,f,t]))))-\\\n",
    "                                 (beta1*pi_ur1[m,u,f,t]*J)\n",
    "            constraint.append(temp3>=actual_lambda_ur[frame,u]*Z_ur*Delta*1e-03)\n",
    "        for m in range(M):\n",
    "            temp5 = 0\n",
    "            for u in range(U_ur):\n",
    "                temp4 = 0\n",
    "                for t in range(t2):\n",
    "                    for f in range(f2):\n",
    "                        temp4 += ((beta2/0.6931)*(cp.log(1+(g_ur2[m,u,f,t]*y_ur2[m,u,f,t])))-\\\n",
    "                                    (beta2*pi_ur2[m,u,f,t]*J))*delta2\n",
    "                for t in range(t1):\n",
    "                    for f in range(f1):\n",
    "                        temp4 += ((beta1/0.6931)*(cp.log(1+(g_ur1[m,u,f,t]*y_ur1[m,u,f,t])))-\\\n",
    "                                    (beta1*pi_ur1[m,u,f,t]*J))*delta1\n",
    "                temp5 += V[m,u]*actual_lambda_ur[frame,u]*Z_ur*Delta*1e-03 - temp4\n",
    "            for u in range(U_em):\n",
    "                temp4 = 0\n",
    "                for t in range(t2):\n",
    "                    for f in range(f2):\n",
    "                        temp4 += ((beta2/0.6931)*(cp.log(1+(g_em2[m,u,f,t]*y_em2[m,u,f,t]))))*delta2\n",
    "                for t in range(t1):\n",
    "                    for f in range(f1):\n",
    "                        temp4 += ((beta1/0.6931)*(cp.log(1+(g_em1[m,u,f,t]*y_em1[m,u,f,t]))))*delta1\n",
    "                temp5 += V[m,u+U_ur]*actual_lambda_em[frame,u]*Z_em*Delta - temp4\n",
    "            constraint.append(cp.maximum(temp5,0)<=Q_max)\n",
    "        # Solve problem\n",
    "        prob = cp.Problem(objective, constraint)\n",
    "        prob.solve(solver = cp.ECOS) \n",
    "        output = prob.status\n",
    "        \n",
    "    except cp.SolverError:\n",
    "        output = 'non_feasible'   \n",
    "\n",
    "    r_em1, r_em2, r_em, r_ur = np.zeros((M,U_em)), np.zeros((M,U_em)), np.zeros((M,U_em)), np.zeros((M,U_ur))\n",
    "    print('Output is:', output)\n",
    "    if  output== 'optimal' or output == 'optimal_inaccurate':\n",
    "        p_em2, p_em1 = np.zeros((M,U_em,f2, t2)), np.zeros((M,U_em,f1, t1))\n",
    "        p_ur2, p_ur1 = np.zeros((M,U_ur,f2, t2)), np.zeros((M,U_ur,f1, t1))\n",
    "        #urllc and embb rate \n",
    "        for m in range(M):\n",
    "            for u in range(U_em):\n",
    "                temp, tempp = 0, 0\n",
    "                for f in range(f2):\n",
    "                    for t in range(t2):\n",
    "                        p_em2[m,u,f,t] = y_em2[m,u,f,t].value\n",
    "                        temp += beta2*np.log2(1+g_em2[m,u,f,t]*p_em2[m,u,f,t])\n",
    "                r_em2[m,u] = temp\n",
    "                tempp += temp\n",
    "                temp = 0\n",
    "                for f in range(f1):\n",
    "                    for t in range(t1):\n",
    "                        p_em1[m,u,f,t] = y_em1[m,u,f,t].value\n",
    "                        temp += beta1*np.log2(1+g_em1[m,u,f,t]*p_em1[m,u,f,t])\n",
    "                r_em1[m,u] = temp\n",
    "                tempp += temp\n",
    "                r_em[m,u]= tempp\n",
    "            for u in range(U_ur):\n",
    "                temp = 0\n",
    "                for f in range(f2):\n",
    "                    for t in range(t2):\n",
    "                        p_ur2[m,u,f,t] = y_ur2[m,u,f,t].value\n",
    "                        temp += beta2*np.log2(1+g_ur2[m,u,f,t]*p_ur2[m,u,f,t])-(beta2*pi_ur2[m,u,f,t]*J)\n",
    "                for f in range(f1):\n",
    "                    for t in range(t1):\n",
    "                        p_ur1[m,u,f,t] = y_ur1[m,u,f,t].value\n",
    "                        temp += beta1*np.log2(1+g_ur1[m,u,f,t]*p_ur1[m,u,f,t])-(beta1*pi_ur1[m,u,f,t]*J)\n",
    "                r_ur[m,u] = temp\n",
    "                if r_ur[m,u]<0:\n",
    "                    r_ur[m,u]=0\n",
    "        print('r_ur', np.sum(r_ur))\n",
    "        print('r_em', np.sum(r_em))\n",
    "        ReWard2 = np.sum(r_em2)\n",
    "        ReWard1 = np.sum(r_em1)\n",
    "        Flag1 *= 1\n",
    "        Flag2 *= 1\n",
    "        #Update queue_length\n",
    "        for m in range(M):\n",
    "            for u in range(U_ur):\n",
    "                temp4 = 0\n",
    "                for t in range(t2):\n",
    "                    for f in range(f2):\n",
    "                        temp4 += (beta2*(np.log2(1+(g_ur2[m,u,f,t]*p_ur2[m,u,f,t])))-\\\n",
    "                                    (beta2*pi_ur2[m,u,f,t]*J))*delta2\n",
    "                for t in range(t1):\n",
    "                    for f in range(f1):\n",
    "                        temp4 += (beta1*(np.log2(1+(g_ur1[m,u,f,t]*p_ur1[m,u,f,t])))-\\\n",
    "                                    (beta1*pi_ur1[m,u,f,t]*J))*delta1\n",
    "                q[m,u] = q[m,u] + V[m,u]*actual_lambda_ur[frame,u]*Z_ur*Delta*1e-03 - temp4\n",
    "            for u in range(U_em):\n",
    "                temp4 = 0\n",
    "                for t in range(t2):\n",
    "                    for f in range(f2):\n",
    "                        temp4 += (beta2*(np.log2(1+(g_em2[m,u,f,t]*p_em2[m,u,f,t]))))*delta2\n",
    "                for t in range(t1):\n",
    "                    for f in range(f1):\n",
    "                        temp4 += (beta1*(np.log2(1+(g_em1[m,u,f,t]*p_em1[m,u,f,t]))))*delta1\n",
    "                q[m,u+U_ur] = q[m,u+U_ur] + V[m,u+U_ur]*actual_lambda_em[frame,u]*Z_em*Delta - temp4\n",
    "        for m in range(M):\n",
    "            for u in range(U):\n",
    "                if q[m,u] < 0:\n",
    "                    q[m,u] = 0\n",
    "        #Update \\varphi\n",
    "        for m in range(M):\n",
    "            for u in range(U_ur):\n",
    "                if r_ur[m,u] > 0 and np.sum(r_ur[:,u]) > 0:\n",
    "                    V[m,u] = r_ur[m,u]/np.sum(r_ur[:,u])\n",
    "                else:\n",
    "                    V[m,u] = 0\n",
    "            for u in range(U_em):\n",
    "                if r_em[m,u] > 0 and np.sum(r_em[:,u]) > 0:\n",
    "                    V[m,u+U_ur] = r_em[m,u]/np.sum(r_em[:,u])\n",
    "                else:\n",
    "                    V[m,u+U_ur] = 0\n",
    "    else:\n",
    "        Flag1 *= 0\n",
    "        Flag2 *= 0\n",
    "        ReWard1, ReWard2 = 0, 0\n",
    "        #update q\n",
    "        for m in range(M):\n",
    "            for u in range(U_ur):\n",
    "                q[m,u] += (V[m,u]*actual_lambda_ur[frame,u]*Z_ur*Delta*1e-03)\n",
    "            for u in range(U_em):\n",
    "                q[m,u+U_ur] += (V[m,u+U_ur]*actual_lambda_em[frame,u]*Z_em*Delta)\n",
    "        #update varphi\n",
    "        V = np.zeros((M,U))      \n",
    "        for u in range(U):\n",
    "            for m in range(M):\n",
    "                V[m,u] = 1/M\n",
    "        #update power\n",
    "        p_em2, p_em1 = np.zeros((M,U_em,f2, t2)), np.zeros((M,U_em,f1, t1))\n",
    "        p_ur2, p_ur1 = np.zeros((M,U_ur,f2, t2)), np.zeros((M,U_ur,f1, t1))\n",
    "        pp = P_max/(U*(f1+(2*f2)))\n",
    "        for m in range(M):\n",
    "            for t in range(t1):\n",
    "                p_em1[m,:,:,t] = pp*np.ones((U_em,f1))\n",
    "                p_ur1[m,:,:,t] = pp*np.ones((U_ur,f1))\n",
    "            for t in range(t2):\n",
    "                p_em2[m,:,:,t] = pp*np.ones((U_em,f2))\n",
    "                p_ur2[m,:,:,t] = pp*np.ones((U_ur,f2))\n",
    "    \n",
    "    return ReWard1, ReWard2, Flag1, Flag2, V, q, p_ur2, p_ur1, p_em2, p_em1, np.sum(r_em)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea894e9f",
   "metadata": {},
   "source": [
    "# Step7: run code to train the model offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f96e165",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def binary_action2(action2):\n",
    "    pi_ur2 = np.zeros((M, U_ur, f2, t2))\n",
    "    pi_em2 = np.zeros((M, U_em, f2, t2))\n",
    "    s2 = action2[0:dim2]\n",
    "    c2 = np.zeros((M, U, f2, t2))    \n",
    "    for i, idx in enumerate(range(0, dim2, M*U)):\n",
    "        bb = s2[idx:idx+M*U].reshape(M, U, order='F')\n",
    "        c2[:,:,i // t2, i % t2] = bb               \n",
    "    for u in range(U_ur):\n",
    "        pi_ur2[:,u,:,:] = c2[:,u,:,:]\n",
    "    for u in range(U_em):\n",
    "        pi_em2[:,u,:,:] = c2[:,U_ur+u,:,:]       \n",
    "    return pi_ur2, pi_em2\n",
    "\n",
    "def binary_action1(action1):\n",
    "    pi_ur1 = np.zeros((M, U_ur, f1, t1))\n",
    "    pi_em1 = np.zeros((M, U_em, f1, t1))\n",
    "    s1 = action1[0:dim1]\n",
    "    c1 = np.zeros((M, U, f1, t1))    \n",
    "    for i, idx in enumerate(range(0, dim1, M*U)):\n",
    "        bb = s1[idx:idx+M*U].reshape(M, U, order='F')\n",
    "        c1[:,:,i // t1, i % t1] = bb               \n",
    "    for u in range(U_ur):\n",
    "        pi_ur1[:,u,:,:] = c1[:,u,:,:]\n",
    "    for u in range(U_em):\n",
    "        pi_em1[:,u,:,:] = c1[:,U_ur+u,:,:]       \n",
    "    return pi_ur1, pi_em1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    Max_epoch = 20000\n",
    "    Max_episode = 100\n",
    "    Max_frame = 10 \n",
    "    batch_size = 100\n",
    "    \n",
    "    ddqn_agent = DDQNAgent_frq(alpha=0.001, gamma=0.99, epsilon=1.0, batch_size= 100,\n",
    "                               n_actions2=nA2, input_dims2=nS2, n_actions1=nA1, input_dims1=nS1)\n",
    "    \n",
    "    Score_episode2, Avg_Score_episode2, Score_epoch2, Avg_Score_epoch2 = [], [], [], []\n",
    "    Score_episode1, Avg_Score_episode1, Score_epoch1, Avg_Score_epoch1 = [], [], [], []\n",
    "    Epsilon_hist, LOSS2, LOSS1, COUNTER = [], [], [], []\n",
    "\n",
    "    for epoch in range(Max_epoch):\n",
    "        SCORE2, SCORE1 = 0,0\n",
    "        \n",
    "        for episode in range(Max_episode):\n",
    "            print(\"***** epoch\", epoch, 'episode', episode, \"*****\")\n",
    "            \n",
    "            #reset env\n",
    "            start_frame = Max_frame*episode\n",
    "            end_frame = Max_frame*episode + Max_frame\n",
    "            H_ur1,H_ur2,H_em1,H_em2,pl_ur1,pl_ur2,pl_em1,pl_em2,state1,state2,V,q= initial_frq(start_frame)\n",
    "            done = False\n",
    "            score2 ,score1 = 0, 0\n",
    "            counter = 0\n",
    "            \n",
    "            for frame in range(start_frame, end_frame):\n",
    "                print(\"***** frame\", frame, \"*****\") \n",
    "                \n",
    "                action2, mode = ddqn_agent.choose_action2(state2, nS2)\n",
    "                print('we choose action2 with:', mode)\n",
    "                action1, mode = ddqn_agent.choose_action1(state1, nS1)\n",
    "                print('we choose action1 with:', mode)\n",
    "                print('queue:', np.sum(q))\n",
    "                #reshape action to desired shape\n",
    "                pi_ur2, pi_em2 = binary_action2(action2)\n",
    "                pi_ur1, pi_em1 = binary_action1(action1) \n",
    "                state_1,state_2,reward1,reward2,done,Hh_ur1,Hh_em1,Hh_ur2,Hh_em2,Vv,qq,Flag, r_em, tt_ur=envornmt_frq(pi_ur1,\n",
    "                pi_em1, pi_ur2, pi_em2,frame, end_frame, P_max, H_ur1, H_ur2, H_em1,H_em2, pl_ur1, pl_ur2, pl_em1, pl_em2,V,q)\n",
    "                \n",
    "                print('reward1, reward2 is:', reward1, reward2)\n",
    "                score2 += reward2\n",
    "                score1 += reward1\n",
    "                print('total number of ur2 RBs:', np.sum(pi_ur2))\n",
    "                print('total number of ur1 RBs:', np.sum(pi_ur1))\n",
    "                print('total number of em2 RBs:', np.sum(pi_em2[:,0,:,:]), np.sum(pi_em2[:,1,:,:]))\n",
    "                print('total number of em1 RBs:', np.sum(pi_em1[:,0,:,:]), np.sum(pi_em1[:,1,:,:]))\n",
    "                \n",
    "                if Flag==1:\n",
    "                    counter +=1\n",
    "                    print('Yesss, you can... :)')\n",
    "                \n",
    "                state2 = state2.reshape(nS2,)\n",
    "                state_2 = state_2.reshape(nS2,)\n",
    "                action2 = action2.reshape(nA2,)\n",
    "                state1 = state1.reshape(nS1,)\n",
    "                state_1 = state_1.reshape(nS1,)\n",
    "                action1 = action1.reshape(nA1,)\n",
    "                \n",
    "                state_mmry = ddqn_agent.remember(state1, action1, reward1, state_1, state2, action2, reward2, state_2, Flag, done)\n",
    "\n",
    "                loss2 = ddqn_agent.learn()\n",
    "                LOSS2.append(loss2)\n",
    "\n",
    "                state2 = np.copy(state_2)\n",
    "                state1 = np.copy(state_1)\n",
    "                H_ur2,H_em2 = np.copy(Hh_ur2),np.copy(Hh_em2)\n",
    "                H_ur1,H_em1 = np.copy(Hh_ur1),np.copy(Hh_em1)\n",
    "                V, q = np.copy(Vv) ,np.copy(qq)\n",
    "                \n",
    "            COUNTER.append(counter)\n",
    "            Score_episode1.append(score1)\n",
    "            Avg_Score_episode1.append(np.mean(Score_episode1[max(0, len(Score_episode1)-40):(len(Score_episode1)+1)]))\n",
    "            Score_episode2.append(score2)\n",
    "            Avg_Score_episode2.append(np.mean(Score_episode2[max(0, len(Score_episode2)-40):(len(Score_episode2)+1)]))\n",
    "            Epsilon_hist.append(ddqn_agent.epsilon)\n",
    "            print('Epsilon_hist is:', Epsilon_hist[-1])\n",
    "            \n",
    "            if episode % 5 == 0 and episode > 0:\n",
    "                plt.grid(linestyle='--')\n",
    "                plt.plot(Score_episode1, color='lightgray')\n",
    "                plt.plot(Avg_Score_episode1, color='b')\n",
    "                plt.xlabel(\"Episode\")\n",
    "                plt.ylabel(\"Reward1\")\n",
    "                plt.legend(['Reward1', 'Average_reward1'])\n",
    "                plt.show()\n",
    "                plt.grid(linestyle='--')\n",
    "                plt.plot(Score_episode2, color='lightgray')\n",
    "                plt.plot(Avg_Score_episode2, color='b')\n",
    "                plt.xlabel(\"Episode\")\n",
    "                plt.ylabel(\"Reward2\")\n",
    "                plt.legend(['Reward2', 'Average_reward2'])\n",
    "                plt.show()\n",
    "                plt.grid(linestyle='--')\n",
    "                plt.plot(COUNTER, color='b')\n",
    "                plt.xlabel(\"Episode\")\n",
    "                plt.ylabel(\"Episode success rate\")\n",
    "                plt.show()\n",
    "                plt.grid(linestyle='--')\n",
    "                plt.plot(LOSS2, color='b')\n",
    "                plt.xlabel(\"Epoch\")\n",
    "                plt.ylabel(\"loss2\")\n",
    "                plt.show()\n",
    "        \n",
    "        SCORE1 += np.mean(Score_episode1[-Max_episode:])\n",
    "        Score_epoch1.append(SCORE1)\n",
    "        Avg_Score_epoch1.append(np.mean(Score_epoch1[max(0, epoch-10):(epoch+1)]))\n",
    "        SCORE2 += np.mean(Score_episode2[-Max_episode:])\n",
    "        Score_epoch2.append(SCORE2)\n",
    "        Avg_Score_epoch2.append(np.mean(Score_epoch2[max(0, epoch-10):(epoch+1)]))\n",
    "        print('********************************')\n",
    "        print('epoch ', epoch, 'score %.2f' %SCORE1, 'average score per epoch %.2f' %Avg_Score_epoch1[epoch])\n",
    "        print('epoch ', epoch, 'score %.2f' %SCORE2, 'average score per epoch %.2f' %Avg_Score_epoch2[epoch])\n",
    "        print('********************************')\n",
    "        if epoch % 10 == 0 and epoch > 0:\n",
    "            ddqn_agent.save_model()\n",
    "            # Register the custom activation function\n",
    "            tensorflow.keras.utils.get_custom_objects()['binary_softmax2'] = binary_softmax2\n",
    "            tensorflow.keras.utils.get_custom_objects()['binary_softmax1'] = binary_softmax1\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d73f709",
   "metadata": {},
   "source": [
    "# Step8: Save scores and call trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45752515",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"Score_episode1_frq.csv\", Score_episode1, delimiter=',')\n",
    "np.savetxt(\"Score_episode2_frq.csv\", Score_episode2, delimiter=',')\n",
    "np.savetxt(\"Avg_Score_episode1_frq.csv\", Avg_Score_episode1, delimiter=',')\n",
    "np.savetxt(\"Avg_Score_episode2_frq.csv\", Avg_Score_episode2, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff8398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call trained model\n",
    "Model_1 = load_model('agent1_frq.h5')\n",
    "Model_1.summary()\n",
    "Model_2 = load_model('agent2_frq.h5')\n",
    "Model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ccb4f2",
   "metadata": {},
   "source": [
    "# Step9: Test Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4df3968",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_frame = 1000\n",
    "end_frame = 1100\n",
    "\n",
    "rate_em = []\n",
    "latency_ur = []\n",
    "queue = []\n",
    "\n",
    "H_ur1,H_ur2,H_em1,H_em2,pl_ur1,pl_ur2,pl_em1,pl_em2,state1,state2,V,q= initial_frq(start_frame)\n",
    "\n",
    "for frame in range(start_frame,end_frame):\n",
    "    state1 = state1.reshape(1,nS1)\n",
    "    action1 = Model_1.predict(state1)\n",
    "    state2 = state2.reshape(1,nS2)\n",
    "    action2 = Model_2.predict(state2)\n",
    "    #reshape action to desired shape\n",
    "    pi_ur2, pi_em2 = binary_action2(action2[0])\n",
    "    pi_ur1, pi_em1 = binary_action1(action1[0])\n",
    "    state_1, state_2, Reward1, Reward2, done, Hh_ur1, Hh_em1, Hh_ur2, Hh_em2, Vv, qq, Flag,r_em,t_ur=envornmt_frq(pi_ur1,\n",
    "    pi_em1, pi_ur2, pi_em2,frame, end_frame, P_max, H_ur1, H_ur2, H_em1,H_em2, pl_ur1, pl_ur2, pl_em1, pl_em2,V,q)\n",
    "    print('total number of ur2 RBs:', np.sum(pi_ur2))\n",
    "    print('total number of ur1 RBs:', np.sum(pi_ur1))\n",
    "    print('total number of em2 RBs:', np.sum(pi_em2))\n",
    "    print('total number of em1 RBs:', np.sum(pi_em1))\n",
    "    print('Flag', Flag)\n",
    "    state2 = np.copy(state_2)\n",
    "    state1 = np.copy(state_1)\n",
    "    H_ur2,H_em2 = np.copy(Hh_ur2),np.copy(Hh_em2)\n",
    "    H_ur1,H_em1 = np.copy(Hh_ur1),np.copy(Hh_em1)\n",
    "    V, q = np.copy(Vv) ,np.copy(qq)\n",
    "    rate_em.append(np.sum(r_em))\n",
    "    latency_ur.append(t_ur)\n",
    "    queue.append(np.sum(qq))\n",
    "                \n",
    "print(np.mean(rate_em))\n",
    "print(np.mean(latency_ur))\n",
    "print(np.mean(queue))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
